{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## This tutorial will explain how to compare data collected in GC logs to external data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# `Step 1`: Gather a dataset you would like to compare to a GC log. I will use the number of bytes in the bytecode for the method being compiled during runtime as an external non-gc source, to see if there is a relationship.\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Import pandas to read the file\n",
    "import pandas as pd \n",
    "\n",
    "# Read in the dataframe, where the string below is the path to the file. Data generated using JVM flag -XX:+PrintCompilation\n",
    "csv_data = pd.read_csv(\"just-in-time.csv\")\n",
    "\n",
    "print (csv_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          27   1\n",
      "0         27  42\n",
      "1         27  56\n",
      "2         28  36\n",
      "3         28  46\n",
      "4         28  60\n",
      "...      ...  ..\n",
      "1343  201990   8\n",
      "1344  201990  55\n",
      "1345  201991  18\n",
      "1346  201994  10\n",
      "1347  201995   5\n",
      "\n",
      "[1348 rows x 2 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# `Step 2` : Organize your data such that it fits the \"gc_event_dataframe\" column expectation: Timestamps should go into `TimeFromStart_seconds`, a eventType can go into `EventType`, and your corresponding data can go into `Duration_miliseconds`\n",
    " In this example, we will create a new empty dataframe with the correct columns, the fill those columns with values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.read_log_file import columnNames\n",
    "column_names = columnNames()\n",
    " # print(column_names)\n",
    "new_dataframe = pd.DataFrame() # Creates a new, empty, dataframe\n",
    "\n",
    "for column in column_names:\n",
    "    new_dataframe[column] = \"\"\n",
    "\n",
    "new_dataframe[\"TimeFromStart_seconds\"] = csv_data.iloc[:, 0]\n",
    "new_dataframe[\"Duration_miliseconds\"] = csv_data.iloc[:, 1]\n",
    "event_type_list = [\"Just-In-Time\" for i in range(len(new_dataframe[\"EventType\"]))]\n",
    "new_dataframe[\"EventType\"] = event_type_list\n",
    "# print(new_dataframe)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# `Step 3:` Now that you have a completed dataframe, its time to add it to the dataset being analyzed. Append the gc_event_dataframe to the list of dataframes generated by running log analysis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#################################################################\n",
    "######                                                     ######\n",
    "####  Taken from the original notebook: Set files and run     ####\n",
    "######                                                     ######\n",
    "#################################################################\n",
    "\n",
    "################################################################################################\n",
    "files = [\"workload_gc.log\"]\n",
    "labels = [\"GC workload\", \"Just-in-time data\"] # MAKE SURE TO ADD AN EXTRA LABEL\n",
    "time_range_seconds = None\n",
    "################################################################################################\n",
    "\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../\") \n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "\n",
    "from src.read_log_file import get_parsed_comparions_from_files \n",
    "gc_event_dataframes = get_parsed_comparions_from_files(files, time_range_seconds)\n",
    "\n",
    "#### here, append the new data  ####\n",
    "gc_event_dataframes.append(new_dataframe)\n",
    "\n",
    "## Test! ##\n",
    "print(len(gc_event_dataframes))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "\n",
    "# `Step 4`: Take the new cells you created, and insert them ABOVE the normal cells.\n",
    "\n",
    "# `Step 5`: Add the line to \"append the new data\" to the GC event dataframe AFTER the gc_log_analysis has read the file.\n",
    "\n",
    "# `Step 6`: Now, run log analysis normally!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NOTE: THIS CELL IS JUST AN EXAMPLE. Not used for most analysis.\n",
    "\n",
    "\n",
    "\n",
    " My JIT compilation data lives in the file JIT-data. \n",
    " I construct this regex to capture all relevant lines, and create a CSV called just-in-time.csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "\n",
    "import re \n",
    "match_pattern = \"^\\s*(\\d+) *\\d+.*\\((\\d+) bytes\\)(?:$|   made not entrant$)\"\n",
    "timestamps_miliseconds = []\n",
    "bytes_loaded = []\n",
    "for line in open(\"JIT-data\", \"r\"):\n",
    "    match = re.search(match_pattern, line)\n",
    "    if match:\n",
    "        timestamps_miliseconds.append(match.group(1))\n",
    "        bytes_loaded.append(match.group(2))\n",
    "# Now that we have our data, we can create the csv\n",
    "with open(\"just-in-time.csv\", \"w\") as output_file:\n",
    "    for time, byte in zip(timestamps_miliseconds, bytes_loaded):\n",
    "        output_file.write(time + \", \" +  byte + \"\\n\") # WRITE TO THE CSV FILE\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}